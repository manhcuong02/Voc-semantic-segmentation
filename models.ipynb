{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTYN1d2FezdL+zH39deW95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manhcuong02/voc-semantic-segmentation/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ubvaHT-PWTV",
        "outputId": "a81346a3-06e4-4fcf-ee7e-36fcf4e59389"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 timm-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q0cgXnHV7vIk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import timm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "            nn.ReLU()\n",
        "        )"
      ],
      "metadata": {
        "id": "XwEKnOkKQEOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet\n",
        "![](https://www.researchgate.net/publication/334287825/figure/fig2/AS:778191392210944@1562546694325/The-architecture-of-Unet.ppm)"
      ],
      "metadata": {
        "id": "9jkFESEsQUWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.down_sample = nn.MaxPool2d(kernel_size = 2)\n",
        "        self.up_sample = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n",
        "\n",
        "        self.block_down1 = unet_block(3, 64)\n",
        "        self.block_down2 = unet_block(64, 128)\n",
        "        self.block_down3 = unet_block(128, 256)\n",
        "        self.block_down4 = unet_block(256, 512)\n",
        "\n",
        "        self.neck = unet_block(512, 1024)\n",
        "\n",
        "\n",
        "        self.block_up1 = unet_block(1024 + 512, 512)\n",
        "        self.block_up2 = unet_block(512 + 256, 256)\n",
        "        self.block_up3 = unet_block(256 + 128, 128)\n",
        "        self.block_up4 = unet_block(128 + 64, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, num_classes, kernel_size = 1, stride = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch_size, channels, height, width\n",
        "        x = self.block_down1(x)\n",
        "        x1 = x.clone()\n",
        "\n",
        "        x = self.down_sample(x)\n",
        "        x = self.block_down2(x)\n",
        "        x2 = x.clone()\n",
        "\n",
        "        x = self.down_sample(x)\n",
        "        x = self.block_down3(x)\n",
        "        x3 = x.clone()\n",
        "\n",
        "        x = self.down_sample(x)\n",
        "        x = self.block_down4(x)\n",
        "        x4 = x.clone()\n",
        "\n",
        "        x = self.down_sample(x)\n",
        "        x = self.neck(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x4, x], dim = 1\n",
        "        )\n",
        "        x = self.block_up1(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x3, x], dim = 1\n",
        "        )\n",
        "        x = self.block_up2(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x2, x], dim = 1\n",
        "        )\n",
        "        x = self.block_up3(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x1, x], dim = 1\n",
        "        )\n",
        "        x = self.block_up4(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "3n4hSBdGTIyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet + Unet\n",
        "- replace backbone to ResNet"
      ],
      "metadata": {
        "id": "qKE_j3ieQH31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResUNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.down_sample = nn.MaxPool2d(kernel_size = 2)\n",
        "        self.up_sample = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n",
        "\n",
        "        # source: https://huggingface.co/docs/timm/feature_extraction#multiscale-feature-maps-feature-pyramid\n",
        "        self.backbone = timm.create_model(model_name = 'resnet101', pretrained = True, features_only = True)\n",
        "\n",
        "        self.block_up1 = unet_block(2048 + 1024, 1024)\n",
        "        self.block_up2 = unet_block(1024 + 512, 512)\n",
        "        self.block_up3 = unet_block(512 + 256, 256)\n",
        "        self.block_up4 = unet_block(256 + 64, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, num_classes, kernel_size = 1, stride = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch_size, channels, height, width\n",
        "        x1, x2, x3, x4, x5 = self.backbone(x)\n",
        "\n",
        "        x = self.up_sample(x5)\n",
        "        x = torch.cat(\n",
        "            [x, x4], dim = 1\n",
        "        )\n",
        "        x = self.block_up1(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x, x3], dim = 1\n",
        "        )\n",
        "        x = self.block_up2(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x, x2], dim = 1\n",
        "        )\n",
        "        x = self.block_up3(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.cat(\n",
        "            [x, x1], dim = 1\n",
        "        )\n",
        "        x = self.block_up4(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "_ajK6_7VPwCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet\n",
        "![](https://production-media.paperswithcode.com/methods/new_pspnet-eps-converted-to.jpg)"
      ],
      "metadata": {
        "id": "4aOflnd6Q-tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pyramid Pooling Module\n",
        "class PPM(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bins):\n",
        "        super().__init__()\n",
        "        self.features = []\n",
        "        for bin in bins:\n",
        "            self.features.append(nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(bin),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        self.features = nn.ModuleList(self.features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch, channels, height, width\n",
        "        x_size = x.size()\n",
        "        out = [x]\n",
        "        for f in self.features:\n",
        "            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n",
        "        return torch.cat(out, 1)\n"
      ],
      "metadata": {
        "id": "M1zyQh7kRAoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, num_classes, dropout = 0.1, backbone = 'resnet101', bins = [1, 2, 3, 6]):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained = True, features_only = True)\n",
        "\n",
        "        self.layer0 = nn.Sequential(\n",
        "            self.backbone.conv1, self.backbone.bn1, self.backbone.act1, self.backbone.maxpool\n",
        "        )\n",
        "\n",
        "        self.layer1 = self.backbone.layer1\n",
        "        self.layer2 = self.backbone.layer2\n",
        "        self.layer3 = self.backbone.layer3\n",
        "        self.layer4 = self.backbone.layer4\n",
        "\n",
        "\n",
        "        # mở rộng Receptive field (kích thước vùng đầu vào để tính feature map).\n",
        "        for n, m in self.layer3.named_modules():\n",
        "            if 'conv2' in n:\n",
        "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
        "            elif 'downsample.0' in n:\n",
        "                m.stride = (1, 1)\n",
        "\n",
        "        for n, m in self.layer4.named_modules():\n",
        "            if 'conv2' in n:\n",
        "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
        "            elif 'downsample.0' in n:\n",
        "                m.stride = (1, 1)\n",
        "\n",
        "        feature_dims = 2048\n",
        "        self.ppm = PPM(feature_dims, feature_dims//(len(bins)), bins)\n",
        "\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Conv2d(feature_dims*2, 512, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=dropout),\n",
        "            nn.Conv2d(512, num_classes, kernel_size=1)\n",
        "        )\n",
        "        if self.training:\n",
        "            self.aux_layer = nn.Sequential(\n",
        "                nn.Conv2d(1024, 256, kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(p=dropout),\n",
        "                nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # B, C, H, W\n",
        "        x_size = x.shape\n",
        "        h,w = x_size[2:]\n",
        "\n",
        "        # backbone: forward\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x_tmp = self.layer3(x)\n",
        "        x = self.layer4(x_tmp)\n",
        "\n",
        "        # Pyramid Pooling Module forward\n",
        "        x = self.ppm(x)\n",
        "\n",
        "        # head\n",
        "        x = self.cls(x)\n",
        "\n",
        "        x = F.interpolate(x, size = (h,w), mode = 'bilinear', align_corners = True)\n",
        "\n",
        "        if self.training:\n",
        "            aux = self.aux_layer(x_tmp)\n",
        "            aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n",
        "            return x, aux\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "GKCXdw7NRf6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSPNet + Unet\n",
        "![](https://ars.els-cdn.com/content/image/1-s2.0-S0010482522011866-gr1.jpg)"
      ],
      "metadata": {
        "id": "srBrbVrsRogh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PSPUnet(nn.Module):\n",
        "    def __init__(self, num_classes, bins = [1, 2, 3, 6], backbone = 'resnet101'):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone, pretrained = True, features_only = True)\n",
        "\n",
        "        self.ppm1 = PPM(1024, 1024//len(bins), bins)\n",
        "        self.ppm2 = PPM(512, 512//len(bins), bins)\n",
        "        self.ppm3 = PPM(256, 256//len(bins), bins)\n",
        "        self.ppm4 = PPM(64, 64//len(bins), bins)\n",
        "\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        self.up_sample = nn.Upsample(scale_factor = 2, mode = 'bilinear')\n",
        "        self.block_up1 = unet_block(2048 + 2048, 1024)\n",
        "        self.block_up2 = unet_block(1024 + 1024, 512)\n",
        "        self.block_up3 = unet_block(512 + 512, 256)\n",
        "        self.block_up4 = unet_block(256 + 64*2, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2, x3, x4, x5 = self.backbone(x)\n",
        "\n",
        "        x = self.up_sample(x5)\n",
        "        x = torch.concat(\n",
        "            [x, self.ppm1(x4)], dim = 1\n",
        "        )\n",
        "        x = self.block_up1(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.concat(\n",
        "            [x, self.ppm2(x3)], dim = 1\n",
        "        )\n",
        "        x = self.block_up2(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.concat(\n",
        "            [x, self.ppm3(x2)], dim = 1\n",
        "        )\n",
        "        x = self.block_up3(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = torch.concat(\n",
        "            [x, self.ppm4(x1)], dim = 1\n",
        "        )\n",
        "        x = self.block_up4(x)\n",
        "\n",
        "        x = self.up_sample(x)\n",
        "        x = self.cls(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "NcjcvRNlRm8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Pyramid Network\n",
        "![](https://d3i71xaburhd42.cloudfront.net/7aae14c686757ba33d49c49aef4193038a4a7529/3-Figure2-1.png)"
      ],
      "metadata": {
        "id": "2ymgD_DaW0t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FeaturePyramid(in_channel_list, out_channels, device = 'cuda'):\n",
        "    if isinstance(device, str):\n",
        "        if (device == 'cuda' or device == 'gpu') and torch.cuda.is_available():\n",
        "            device = torch.device(device)\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "\n",
        "    features = []\n",
        "    for in_channels in in_channel_list:\n",
        "        features.append(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, device = device)\n",
        "        )\n",
        "    return features\n",
        "\n",
        "def conv3_block(in_channels, out_channels, num_block = 4, device = 'cuda'):\n",
        "    if isinstance(device, str):\n",
        "        if (device == 'cuda' or device == 'gpu') and torch.cuda.is_available():\n",
        "            device = torch.device(device)\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "    blocks = []\n",
        "    for i in range(num_block):\n",
        "        blocks.append(\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, device = device),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, device = device)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "cdyMT8n1ZjSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FPN(nn.Module):\n",
        "    def __init__(self, backbone_name, out_fpn_channels, num_classes, device = 'cpu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained = True, features_only = True, out_indices = (1,2,3,4))\n",
        "        in_channel_list = self.backbone.feature_info.channels()\n",
        "        self.fpn = FeaturePyramid(in_channel_list, out_fpn_channels, device = 'cpu')\n",
        "        self.blocks = conv3_block(out_fpn_channels, 128, len(in_channel_list), device = 'cpu')\n",
        "\n",
        "        self.conv_cls = nn.Conv2d(512, num_classes, kernel_size = 1, stride = 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ori_shape = x.shape[2:]\n",
        "        x = self.backbone(x)\n",
        "\n",
        "        for i, conv in enumerate(self.fpn):\n",
        "            x[i] = conv(x[i])\n",
        "\n",
        "        x1, x2, x3, x4 = x\n",
        "\n",
        "        x3 = F.interpolate(x4, size = x3.shape[2:], mode = 'bilinear') + x3\n",
        "        x2 = F.interpolate(x3, size = x2.shape[2:], mode = 'bilinear') + x2\n",
        "        x1 = F.interpolate(x2, size = x1.shape[2:], mode = 'bilinear') + x1\n",
        "\n",
        "        x = [x1, x2, x3, x4]\n",
        "\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x[i] = block(x[i])\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            x[i] = F.interpolate(x[i], ori_shape, mode = 'bilinear')\n",
        "\n",
        "        x = torch.concat(x, dim = 1)\n",
        "\n",
        "        x = self.conv_cls(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "bX2lnWWCq72N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Pyramid Attention Network\n",
        "![](https://user-images.githubusercontent.com/527241/58665416-1f1ad880-8331-11e9-9a2f-3cf289a1df96.png)"
      ],
      "metadata": {
        "id": "NXAUxpybCE90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/decoders/pan/decoder.py\n",
        "\n",
        "class ConvBnRelu(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int,\n",
        "        stride: int = 1,\n",
        "        padding: int = 0,\n",
        "        dilation: int = 1,\n",
        "        groups: int = 1,\n",
        "        bias: bool = True,\n",
        "        add_relu: bool = True,\n",
        "        interpolate: bool = False,\n",
        "    ):\n",
        "        super(ConvBnRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=padding,\n",
        "            dilation=dilation,\n",
        "            bias=bias,\n",
        "            groups=groups,\n",
        "        )\n",
        "        self.add_relu = add_relu\n",
        "        self.interpolate = interpolate\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        if self.add_relu:\n",
        "            x = self.activation(x)\n",
        "        if self.interpolate:\n",
        "            x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uJOFEpWWCEuz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- FPA Block\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:906/1*JhWWLQsxkJZoyuR-oIxAPA.png)"
      ],
      "metadata": {
        "id": "AS9Du3kZDVyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/decoders/pan/decoder.py\n",
        "class FPABlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, upscale_mode=\"bilinear\"):\n",
        "        super(FPABlock, self).__init__()\n",
        "\n",
        "        self.upscale_mode = upscale_mode\n",
        "        if self.upscale_mode == \"bilinear\":\n",
        "            self.align_corners = True\n",
        "        else:\n",
        "            self.align_corners = False\n",
        "\n",
        "        # global pooling branch\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            ConvBnRelu(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        # midddle branch\n",
        "        self.mid = nn.Sequential(\n",
        "            ConvBnRelu(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                padding=0,\n",
        "            )\n",
        "        )\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBnRelu(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=1,\n",
        "                kernel_size=7,\n",
        "                stride=1,\n",
        "                padding=3,\n",
        "            ),\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBnRelu(in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=2),\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            ConvBnRelu(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "            ConvBnRelu(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
        "        )\n",
        "        self.conv2 = ConvBnRelu(in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv1 = ConvBnRelu(in_channels=1, out_channels=1, kernel_size=7, stride=1, padding=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.size(2), x.size(3)\n",
        "        b1 = self.branch1(x)\n",
        "        upscale_parameters = dict(mode=self.upscale_mode, align_corners=self.align_corners)\n",
        "        b1 = F.interpolate(b1, size=(h, w), **upscale_parameters)\n",
        "\n",
        "        mid = self.mid(x)\n",
        "        x1 = self.down1(x)\n",
        "        x2 = self.down2(x1)\n",
        "        x3 = self.down3(x2)\n",
        "        x3 = F.interpolate(x3, size=(h // 4, w // 4), **upscale_parameters)\n",
        "\n",
        "        x2 = self.conv2(x2)\n",
        "        x = x2 + x3\n",
        "        x = F.interpolate(x, size=(h // 2, w // 2), **upscale_parameters)\n",
        "\n",
        "        x1 = self.conv1(x1)\n",
        "        x = x + x1\n",
        "        x = F.interpolate(x, size=(h, w), **upscale_parameters)\n",
        "\n",
        "        x = torch.mul(x, mid)\n",
        "        x = x + b1\n",
        "        return x"
      ],
      "metadata": {
        "id": "_oP5ksGPC7U9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GAU Block\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1052/1*hxW0710PijUYHe-BCimWoQ.png)"
      ],
      "metadata": {
        "id": "H5ws0PFzDPKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/decoders/pan/decoder.py\n",
        "class GAUBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int, upscale_mode: str = \"bilinear\"):\n",
        "        super(GAUBlock, self).__init__()\n",
        "\n",
        "        self.upscale_mode = upscale_mode\n",
        "        self.align_corners = True if upscale_mode == \"bilinear\" else None\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            ConvBnRelu(\n",
        "                in_channels=out_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=1,\n",
        "                add_relu=False,\n",
        "            ),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.conv2 = ConvBnRelu(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: low level feature\n",
        "            y: high level feature\n",
        "        \"\"\"\n",
        "        h, w = x.size(2), x.size(3)\n",
        "        y_up = F.interpolate(y, size=(h, w), mode=self.upscale_mode, align_corners=self.align_corners)\n",
        "        x = self.conv2(x)\n",
        "        y = self.conv1(y)\n",
        "        z = torch.mul(x, y)\n",
        "        return y_up + z"
      ],
      "metadata": {
        "id": "BGAQG680C-NN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FPANet(nn.Module):\n",
        "    def __init__(self, num_classes, backbone_name = 'resnet101'):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained = True, features_only = True)\n",
        "        self.fpa_block = FPABlock(in_channels = 2048, out_channels = num_classes)\n",
        "\n",
        "        self.gau_block1 = GAUBlock(in_channels = 1024, out_channels = num_classes)\n",
        "        self.gau_block2 = GAUBlock(in_channels = 512, out_channels = num_classes)\n",
        "        self.gau_block3 = GAUBlock(in_channels = 256, out_channels = num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_shape = x.shape\n",
        "        x1, x2, x3, x4, x5 = self.backbone(x)\n",
        "\n",
        "        x = self.fpa_block(x5)\n",
        "\n",
        "        x = self.gau_block1(x4, x)\n",
        "        x = self.gau_block2(x3, x)\n",
        "        x = self.gau_block3(x2, x)\n",
        "\n",
        "        x = F.interpolate(x, size = x_shape[2:], mode = 'bilinear')\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "DV7BQYcxEDwx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = timm.create_model('resnet101', pretrained = True, features_only = True)\n",
        "model = FPANet(num_classes = 5, backbone_name = 'resnet101')\n",
        "x = torch.rand(2,3,256,256)\n",
        "y = model(x)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EWyLCwbS0-l",
        "outputId": "af1502a0-86df-4896-d0fd-6942a2c7c8d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = timm.create_model('resnet101', pretrained = True, features_only = True)\n",
        "x = torch.rand(2,3,256,256)\n",
        "y = a(x)\n",
        "for i in y:\n",
        "    print(i.shape)"
      ],
      "metadata": {
        "id": "2x3vpqHZS1hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b06f9cc-be00-4e3f-dec2-2502a2cc2f35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 64, 128, 128])\n",
            "torch.Size([2, 256, 64, 64])\n",
            "torch.Size([2, 512, 32, 32])\n",
            "torch.Size([2, 1024, 16, 16])\n",
            "torch.Size([2, 2048, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WHdfRD7hoyi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}